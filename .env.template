# FinNewsMasterV1 Environment Configuration
# 使用的时候，把 .env.template 复制一份，重命名为 .env(删掉原来的.env），然后填写你的 API Key

# --- LLM Hardware Config ---
# 模式选择: 'local' (Ollama) 或 'deepseek' (云端 API)
# 如使用local，需要先安装并启用ollama，拉取模型，并且把下面的模型名改为你拉取的模型名
LLM_PROVIDER=deepseek

# --- Local Ollama Config ---
OLLAMA_BASE_URL=http://localhost:11434
# 本地模型名字
LOCAL_MODEL_NAME=qwen3:8b

# --- DeepSeek API Config ---
# DeepSeek 官方 API 地址 (固定这个即可)
DEEPSEEK_BASE_URL=https://api.deepseek.com
# 模型选择: deepseek-chat (通用 V3) 或 deepseek-coder (代码/数学强)
DEEPSEEK_MODEL_NAME=deepseek-chat
# 填入你的 API Key (以 sk- 开头)
DEEPSEEK_API_KEY=sk-xxxxxxxxxxxxxxxxxx



# 4060 显存保护：限制并发推理数 （根据显存大小调整）
MAX_GPU_CONCURRENCY=2
# 上下文窗口限制 (防止 OOM)
CONTEXT_WINDOW=4096

GPU_TEMP_LIMIT=80
GPU_TEMP_RESUME=65
GPU_TEMP_CHECK_INTERVAL=5

# --- Crawler Config ---
# Jina Reader 前缀
JINA_READER_BASE=https://r.jina.ai/
# i9 CPU 优势：可以开大并发抓取
MAX_CRAWLER_CONCURRENCY=10
